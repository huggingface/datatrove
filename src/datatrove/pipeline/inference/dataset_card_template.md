---
language:
[[language_block]]
license: [[license_id]]
tags:
[[tags_block]]
annotations_creators:
- machine-generated
language_creators:
- found
pretty_name: [[repo_id]]
size_categories:
- [[size_category]]
source_datasets:
[[source_datasets_block]]
task_categories:
- text-generation
task_ids:
- language-modeling
configs:
- config_name: default
  data_files:
  - split: [[input_dataset_split]]
    path: data/*.parquet
train-eval-index:
- config: default
  task: text-generation
  task_id: language-modeling
  splits:
    train_split: [[input_dataset_split]]
    eval_split:
  col_mapping:
    text: text
---

# Dataset Card for [[repo_id]]

## Dataset Summary

Synthetic data generated by [DataTrove](https://github.com/huggingface/datatrove):
 * Model: `[[model_name]]` (`[[model_revision]]`)
 * Source dataset: `[[source_dataset_full]]` (`[[input_dataset_split]]` split). 
 * Generation config: `temperature=[[temperature]]`, `top_p=[[top_p]]`, `top_k=[[top_k]]`, `max_tokens=[[max_tokens]]`, `model_max_context=[[model_max_context]]`
 * Speculative decoding: `[[spec_config]]`
 * System prompt: `[[system_prompt]]`
 * User prompt: [[user_prompt_info]]

[[stats_summary]]

[[progress_section]]

You can load the dataset using
```python
from datasets import load_dataset

ds = load_dataset("[[repo_id]]")
```

## Dataset Stats

[[job_stats_table]]

## Licensing Information

License: [[license_id]]

## Contributions

Thanks to [@[[hf_user]]](https://huggingface.co/[[hf_user]]) for adding this dataset.
